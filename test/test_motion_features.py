import argparse
import cv2
import numpy as np
from pathlib import Path
import time

from models.motion.motion_features import MotionFeatureManager
from models.video.video_capture import VideoCapture

def main():
    """
    è¿è¡Œæµ‹è¯•åº”ç”¨ç¨‹åºï¼Œå±•ç¤ºåŠ¨æ€ç‰¹å¾æå–åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼?
    - å…‰æµåˆ†æ
    - è¿åŠ¨å†å²
    """
    parser = argparse.ArgumentParser(description='æµ‹è¯•è¿åŠ¨ç‰¹å¾æå–')
    parser.add_argument('--source', type=str, default='0', help='è§†é¢‘æº?(0 è¡¨ç¤ºæ‘„åƒå¤?')
    parser.add_argument('--use_optical_flow', action='store_true', help='ä½¿ç”¨å…‰æµåˆ†æ')
    parser.add_argument('--use_motion_history', action='store_true', help='ä½¿ç”¨è¿åŠ¨å†å²åˆ†æ')
    parser.add_argument('--flow_method', type=str, default='farneback', choices=['farneback', 'pyr_lk'], 
                       help='å…‰æµè®¡ç®—æ–¹æ³• (farneback æˆ?pyr_lk)')
    parser.add_argument('--output_dir', type=str, default='motion_samples', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--use_gpu', action='store_true', help='ä½¿ç”¨GPUåŠ é€?(å¦‚æœå¯ç”¨)')
    parser.add_argument('--history_length', type=int, default=20, help='è¿åŠ¨å†å²å¸§æ•°')
    parser.add_argument('--threshold', type=int, default=30, help='è¿åŠ¨æ£€æµ‹é˜ˆå€?)
    
    args = parser.parse_args()
    
    # ç¡®ä¿è‡³å°‘å¯ç”¨ä¸€ç§ç‰¹å¾æå–æ–¹æ³?
    if not args.use_optical_flow and not args.use_motion_history:
        print("è‡³å°‘éœ€è¦å¯ç”¨ä¸€ç§ç‰¹å¾æå–æ–¹æ³•ï¼Œé»˜è®¤å¯ç”¨å…¨éƒ¨")
        args.use_optical_flow = True
        args.use_motion_history = True
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–è§†é¢‘æº
    cap = VideoCapture(args.source)
    
    # åˆå§‹åŒ–è¿åŠ¨ç‰¹å¾ç®¡ç†å™¨
    motion_manager = MotionFeatureManager(
        use_optical_flow=args.use_optical_flow,
        use_motion_history=args.use_motion_history,
        optical_flow_method=args.flow_method,
        use_gpu=args.use_gpu,
        history_length=args.history_length,
        threshold=args.threshold
    )
    
    # è®¾ç½®æ˜¾ç¤ºçª—å£
    cv2.namedWindow('Motion Features', cv2.WINDOW_NORMAL)
    
    # å¤„ç†è§†é¢‘å¸?
    frame_count = 0
    start_time = time.time()
    paused = False
    show_help = True
    
    while cap.is_opened():
        if not paused:
            ret, frame = cap.read()
            if not ret:
                break
        
        if frame is None:
            continue
        
        # æå–è¿åŠ¨ç‰¹å¾
        features = motion_manager.extract_features(frame)
        
        # å¯è§†åŒ–è¿åŠ¨ç‰¹å¾?
        vis_frame = motion_manager.visualize_features(frame, features)
        
        # å¦‚æœå¯ç”¨äº†è¿åŠ¨å†å²ï¼Œæ˜¾ç¤ºè¿åŠ¨å†å²å›¾åƒ
        if args.use_motion_history:
            mhi = motion_manager.get_motion_history_image()
            if mhi is not None:
                # è½¬æ¢ä¸ºå½©è‰²å›¾åƒä»¥ä¾¿äºæ˜¾ç¤º
                mhi_color = cv2.applyColorMap(mhi, cv2.COLORMAP_JET)
                # è°ƒæ•´å¤§å°ä»¥åŒ¹é…åŸå§‹å¸§
                mhi_color = cv2.resize(mhi_color, (frame.shape[1] // 3, frame.shape[0] // 3))
                # æ”¾ç½®åœ¨åŸå§‹å¸§çš„å³ä¸Šè§’
                vis_frame[10:10+mhi_color.shape[0], vis_frame.shape[1]-mhi_color.shape[1]-10:vis_frame.shape[1]-10] = mhi_color
        
        # æ˜¾ç¤ºå¸§ç‡
        fps = frame_count / (time.time() - start_time + 1e-6)
        cv2.putText(vis_frame, f'FPS: {fps:.1f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # æ˜¾ç¤ºç‰¹å¾è®¡æ•°
        cv2.putText(vis_frame, f'Features: {len(features)}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        if show_help:
            help_text = [
                "æŒ‰é”®æ§åˆ¶:",
                "Q/ESC - é€€å‡?,
                "H - æ˜¾ç¤º/éšè—å¸®åŠ©",
                "ç©ºæ ¼ - æš‚åœ/ç»§ç»­",
                "S - ä¿å­˜å½“å‰å¸?,
                "R - é‡ç½®ç‰¹å¾æå–å™?
            ]
            for i, text in enumerate(help_text):
                cv2.putText(vis_frame, text, (10, 110 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # æ˜¾ç¤ºç»“æœ
        cv2.imshow('Motion Features', vis_frame)
        
        # æŒ‰é”®å¤„ç†
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q') or key == 27:  # q æˆ?ESC
            break
        elif key == ord(' '):  # ç©ºæ ¼
            paused = not paused
        elif key == ord('h'):  # h
            show_help = not show_help
        elif key == ord('s'):  # s
            # ä¿å­˜ç‰¹å¾å¯è§†åŒ–å›¾åƒ?
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            save_path = output_dir / f'motion_features_{timestamp}.jpg'
            cv2.imwrite(str(save_path), vis_frame)
            print(f"å·²ä¿å­˜å›¾åƒåˆ°: {save_path}")
            
            # å¦‚æœæœ‰è¿åŠ¨å†å²å›¾åƒï¼Œä¿å­˜å®?
            if args.use_motion_history:
                mhi = motion_manager.get_motion_history_image()
                if mhi is not None:
                    mhi_path = output_dir / f'motion_history_{timestamp}.jpg'
                    cv2.imwrite(str(mhi_path), mhi)
                    print(f"å·²ä¿å­˜è¿åŠ¨å†å²åˆ°: {mhi_path}")
        elif key == ord('r'):  # r
            # é‡ç½®ç‰¹å¾æå–å™?
            motion_manager.reset()
            frame_count = 0
            start_time = time.time()
            print("å·²é‡ç½®ç‰¹å¾æå–å™¨")
        
        frame_count += 1
    
    # æ¸…ç†
    cap.release()
    cv2.destroyAllWindows()
    print(f"å¤„ç†äº?{frame_count} å¸?)

if __name__ == "__main__":
    main() 
